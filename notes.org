#+TODO: NEXT TODO CHECK | DROP DONE

Lets try keeping notes in this way.



* INBOX

* QUESTIONS

* EXPERIMENTS

* Book

** Chapter 1 - The =Task= Module

*** how to to

The content at the very begginign is quite simple.  At least for me.
The idea than would be to read some part of the book, and only if
needed try to implement it to play around with stuff.  I've started
that way at the very beginning - read some, and than decided that code
base could be beneficial.

What I liked in particular was this process of catching up.  You code,
you know where are you trying to get to, and while trying to this on
your own you see which gaps still do require filling up.

*** pipe of maps rather than map of pipes

I've starting using pipe of maps.

#+begin_src elixir
  email
  |> Enum.map(start_tasks)
  |> Enum.map(collect_results)
#+end_src

I'm never a huge fan of repeating =Enum.map= in each line, so I wanted
to change it into the map of pipe

#+begin_src elixir
  emials
  |> Enum.map(fn email ->
    email
    |> start_task
    |> collect_results
  end)
#+end_src

Those two are equivalent logically, but will produce totally different
result in the runtime.

I think that we would have same issue with =Stream='s combined with
=Task='s. (same issue, or reverse issue) It does look like parallel
implementation, but in fact it is very much synchronous.

#+begin_src elixir
  emils
  |> Stream.map(satrt_task)
  |> Stream.map(collect_result)
  |> Enum.to_list()
#+end_src

*** =Task.async_stream= does have few interesting options

**** =:max_concurrency=

Still, each data is processed in brand new process.  There is simply
limit on how many of them is at the same time.

**** =:ordered=

Still, all the data in each step is processed as soon as possible.  We
are buffering some data before sending it forward to the next step in
the stream.

**** TODO =:on_timeout=

With =:kill_task= value we are able to process whole collection, even
if some tasks do not finish correctly.  You will get ={:error, error}=
for them.  (no original data, and the next step needs to somehow
handle this data :/).
